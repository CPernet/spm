% Simulating the Posner paradigm with free-energy filtering - a demo
%__________________________________________________________________________

% 1) Create a canonical generative model.  This model will be used to create
% stimuli that are more or less familiar (generated by changing the
% parameters to a greater or lesser degree).  The same model is used as a
% neuronal network to simulate event-related responses, both in terms of
% LFPs and PSTH of unit activity.  For simplicity, we will assume the
% generators of LFPs (and PSTHs) are the superficial pyramidal cells that
% encode prediction error.
%==========================================================================
clear
 
% set dimensions for generalised coordinates
%--------------------------------------------------------------------------
G(1).E.d = 2;                          % approximation order
G(1).E.n = 4;                          % embedding order
G(1).E.s = 1/2;                        % temporal smoothness - s.d. of kernel
 
 
% level 1; with lateral inhibition among locations
% 8 stimuli (inputs), 1 cue and 1 timing cue
%--------------------------------------------------------------------------
G(1).m  = 8 + 2;                       % stimuli (inputs)
G(1).n  = 8;                           % hidden states accumlating inputs
G(1).l  = 8 + 1;                       % output channels (locationa)
 
G(1).f  = inline('-sum(x).*x - x + spm_phi(v(1:8) - 2)','x','v','P');
G(1).g  = inline('[8*x; v(9)]','x','v','P');
G(1).V  = exp(8);                      % error variances (output)
G(1).W  = exp(8);                      % error variances (states)
                                       % with a low level of noise
 
% level 2; with state-dependent variance
%--------------------------------------------------------------------------
G(2).ph = inline('[8 - v(10)*8 + kron([1;-1],ones(4,1))*v(9); [8;8]]','x','v','h','M');


% 2) The data: Data [stimuli] are created by integrating the model for some
% input.  The input here is simply a bump [Gaussian] function. 
%==========================================================================

% create inputs and cue 
%--------------------------------------------------------------------------
N       = 32;                          % length of data sequence
U(9,:)  = spm_Ncdf([1:N],N/4,N/8);     % this is the Gaussian spatial cue
U(10,:) = spm_Npdf([1:N],N/2,N/8);     % this is the Gaussian timing cue
U(10,:) = U(10,:)/max(U(10,:));        % this is the Gaussian timing cue

 
% integrate G to obtain causal (v) and hidden states (x)
%--------------------------------------------------------------------------
DEM     = spm_DEM_generate(G,U);
 
% plot causal and hidden states
%--------------------------------------------------------------------------
spm_DEM_qU(DEM.pU)
 
 
% 3) Filerting:  Here we expose the model M to the data and record the
% responses.  The scheme is essential a form of Variational Learning
% that provides an upper bound on perceptual inference and learning.
% We use this bound to simulate neuronal responses, under the assumption
% they are near-optimal.
%==========================================================================
LAP     = spm_LAP(DEM)


% plot the simulated ERPs (see spm_DEM_ERP)
%--------------------------------------------------------------------------
spm_figure('GetWin','ERPs');
spm_dem_ERP(LAP.qU);
 

